Train loss: 2.5385703444480896
Train loss: 1.9898903846740723
Train loss: 1.849217638373375
Train loss: 1.7824615131724963
Train loss: 1.7438773001943315
Train loss: 1.718911381328807

Evaluating on train...
Val loss: 2.3713695406913757, Val f1: 0.4847005605697632
Val loss: 1.9088972091674805, Val f1: 0.3720378279685974
Val loss: 1.7912801504135132, Val f1: 0.35826918482780457
Val loss: 1.7332230372862383, Val f1: 0.35537198185920715
Val loss: 1.7043715289660863, Val f1: 0.3497021496295929
Val loss: 1.6814469660029692, Val f1: 0.34865602850914

Evaluating on test...
Val loss: 3.162134289741516, Val f1: 0.6567801833152771
Val loss: 2.379997670650482, Val f1: 0.48372989892959595
Val loss: 2.1185816526412964, Val f1: 0.426870733499527
Val loss: 1.9847591817378998, Val f1: 0.3977392613887787
new best_f1 reached
filter= [2]drop_first= [0, 1]

starting Epoch 1
Training...
Train loss: 2.5446927547454834
Train loss: 1.9889786005020142
Train loss: 1.849215492606163
Train loss: 1.7836637171831997
Train loss: 1.7455519778387887
Train loss: 1.718765847823199

Evaluating on train...
Val loss: 2.3885127305984497, Val f1: 0.5179923176765442
Val loss: 1.911747932434082, Val f1: 0.4140428602695465
Val loss: 1.794620767235756, Val f1: 0.38631126284599304
Val loss: 1.7397211573340676, Val f1: 0.37195155024528503
Val loss: 1.7068611468587602, Val f1: 0.36673349142074585
Val loss: 1.6854135288911707, Val f1: 0.3599970042705536

Evaluating on test...
Val loss: 3.174391269683838, Val f1: 0.6713515520095825
Val loss: 2.3875925540924072, Val f1: 0.49846649169921875
Val loss: 2.126161217689514, Val f1: 0.43982043862342834
Val loss: 1.9918279349803925, Val f1: 0.41744017601013184
new best_f1 reached
filter= [2]drop_first= [0, 1]

starting Epoch 2
Training...
Train loss: 2.5472980737686157
Train loss: 1.9934027194976807
Train loss: 1.8496696203947067
Train loss: 1.7851053367961536
Train loss: 1.7448761718613761
Train loss: 1.7150035184972428

Evaluating on train...
Val loss: 2.3379546999931335, Val f1: 0.49282199144363403
Val loss: 1.8719173908233642, Val f1: 0.3994259238243103
Val loss: 1.7550346404314041, Val f1: 0.37623319029808044
Val loss: 1.7026555754921653, Val f1: 0.3673056662082672
Val loss: 1.6730376992906844, Val f1: 0.3598468601703644
Val loss: 1.650469843079062, Val f1: 0.35484132170677185

Evaluating on test...
Val loss: 3.100778341293335, Val f1: 0.6690324544906616
Val loss: 2.335500121116638, Val f1: 0.492750883102417
Val loss: 2.0790205796559653, Val f1: 0.4347013533115387
Val loss: 1.9481662809848785, Val f1: 0.40617868304252625
filter= [2]drop_first= [0, 1]

starting Epoch 3
Training...
Train loss: 2.5621944069862366
Train loss: 1.9938556432724
Train loss: 1.8420179635286331
Train loss: 1.7750135443427346
Train loss: 1.7385320663452148
Train loss: 1.711622904328739

Evaluating on train...
Val loss: 2.355818808078766, Val f1: 0.5103285908699036
Val loss: 1.8853467941284179, Val f1: 0.4163516163825989
Val loss: 1.7717169374227524, Val f1: 0.3911875784397125
Val loss: 1.720013217492537, Val f1: 0.3771434724330902
Val loss: 1.6909019351005554, Val f1: 0.37015679478645325
Val loss: 1.6716102642171524, Val f1: 0.36230817437171936

Evaluating on test...
Val loss: 3.151330590248108, Val f1: 0.6770544648170471
Val loss: 2.370538890361786, Val f1: 0.5028750896453857
Val loss: 2.1112130085627236, Val f1: 0.4438152611255646
Val loss: 1.9767139554023743, Val f1: 0.420963853597641
new best_f1 reached
filter= [2]drop_first= [0, 1]

starting Epoch 4
Training...
Train loss: 2.549216568470001
Train loss: 1.9901103496551513
Train loss: 1.846521258354187
Train loss: 1.7778766697103328
Train loss: 1.7387372936521257
Train loss: 1.7110471725463867

Evaluating on train...
Val loss: 2.369337260723114, Val f1: 0.5099457502365112
Val loss: 1.8985352754592895, Val f1: 0.41318655014038086
Val loss: 1.7777736634016037, Val f1: 0.3910331428050995
Val loss: 1.7239069071683017, Val f1: 0.3812545835971832
Val loss: 1.6905739307403564, Val f1: 0.3752691447734833
Val loss: 1.669795372906853, Val f1: 0.36934882402420044

Evaluating on test...
Val loss: 3.1426141262054443, Val f1: 0.677200198173523
Val loss: 2.36532723903656, Val f1: 0.5029003024101257
Val loss: 2.105240980784098, Val f1: 0.4486323893070221
Val loss: 1.97230464220047, Val f1: 0.42470958828926086
new best_f1 reached
filter= [2]drop_first= [0, 1]

starting Epoch 0
Training...
Train loss: 2.548066735267639
Train loss: 1.9844248056411744
Train loss: 1.8452218621969223
Train loss: 1.7807694565166126
Train loss: 1.742911892277854
Train loss: 1.7191848334144144

Evaluating on train...
Val loss: 2.3876291513442993, Val f1: 0.5050581097602844
Val loss: 1.9191826581954956, Val f1: 0.3983321785926819
Val loss: 1.7932751327753067, Val f1: 0.3779127299785614
Val loss: 1.736691572449424, Val f1: 0.3664703369140625
Val loss: 1.7057643703051977, Val f1: 0.3619561195373535
Val loss: 1.682478014160605, Val f1: 0.362006813287735

Evaluating on test...
Val loss: 3.1698156595230103, Val f1: 0.6761731505393982
Val loss: 2.384458303451538, Val f1: 0.5019632577896118
Val loss: 2.123762567838033, Val f1: 0.44363248348236084
Val loss: 1.9885679483413696, Val f1: 0.4205106198787689
filter= [2]drop_first= [0, 1]

starting Epoch 1
Training...
Train loss: 2.539429545402527
Train loss: 1.9799459457397461
Train loss: 1.834996685385704
Train loss: 1.7719900608062744
Train loss: 1.735563039779663
Train loss: 1.7121874304378735

Evaluating on train...
Val loss: 2.3417091369628906, Val f1: 0.5895833373069763
Val loss: 1.8708694934844972, Val f1: 0.4657006859779358
Val loss: 1.7555749863386154, Val f1: 0.4337753355503082
Val loss: 1.7077720165252686, Val f1: 0.4128105938434601
Val loss: 1.6789076583726066, Val f1: 0.40269508957862854
Val loss: 1.6612175913418041, Val f1: 0.3963889479637146

Evaluating on test...
Val loss: 3.1252007484436035, Val f1: 0.7497832775115967
Val loss: 2.352457821369171, Val f1: 0.5533562302589417
Val loss: 2.0943409204483032, Val f1: 0.48994341492652893
Val loss: 1.9619086980819702, Val f1: 0.46257102489471436
new best_f1 reached
filter= [2]drop_first= [0, 1]

starting Epoch 2
Training...
Train loss: 2.5410138964653015
Train loss: 1.9824141979217529
Train loss: 1.8411224335432053
Train loss: 1.7783731438896873
Train loss: 1.7404351575034005
Train loss: 1.7157142933677225

Evaluating on train...
Val loss: 2.3848971724510193, Val f1: 0.5569183230400085
Val loss: 1.9138857841491699, Val f1: 0.44461607933044434
Val loss: 1.7935542315244675, Val f1: 0.41387268900871277
Val loss: 1.739761547608809, Val f1: 0.4017358124256134
Train loss: 2.5423808693885803
Train loss: 1.9891781091690064
Train loss: 1.8458147794008255
Train loss: 1.7795864235271106
Train loss: 1.7419949173927307
Train loss: 1.7161747708040125

Evaluating on train...
Val loss: 2.3650755286216736, Val f1: 0.5237147212028503
Val loss: 1.8864986181259156, Val f1: 0.4277566969394684
Val loss: 1.7764803171157837, Val f1: 0.3925152122974396
Val loss: 1.7211138660257512, Val f1: 0.3745741844177246
Val loss: 1.690269138131823, Val f1: 0.36928823590278625
Val loss: 1.6693055699853336, Val f1: 0.3648407757282257

Evaluating on test...
Val loss: 3.1441348791122437, Val f1: 0.6835635304450989
Val loss: 2.365551173686981, Val f1: 0.5071361064910889
Val loss: 2.1064294576644897, Val f1: 0.4475516974925995
Val loss: 1.9729404747486115, Val f1: 0.4243001341819763
filter= [2]drop_first= [0, 1]

starting Epoch 4
Training...
Train loss: 2.5432348251342773
Train loss: 1.9864253997802734
Train loss: 1.8469519764184952
Train loss: 1.7832335450432517
Train loss: 1.7407721536500114
Train loss: 1.713126399937798

Evaluating on train...
Val loss: 2.350051701068878, Val f1: 0.5415141582489014
Val loss: 1.8951854467391969, Val f1: 0.41863781213760376
Val loss: 1.775671973824501, Val f1: 0.39368706941604614
Val loss: 1.7192619388753718, Val f1: 0.38275080919265747
Val loss: 1.6914100987570626, Val f1: 0.3694116175174713
Val loss: 1.6730989638496847, Val f1: 0.3621469736099243

Evaluating on test...
Val loss: 3.1565346717834473, Val f1: 0.6716712713241577
Val loss: 2.375001907348633, Val f1: 0.4993138909339905
Val loss: 2.1149261792500815, Val f1: 0.44126376509666443
Val loss: 1.979859858751297, Val f1: 0.4190502166748047
filter= [3]drop_first= [0, 1]

starting Epoch 0
Training...
Train loss: 2.5643839240074158
Train loss: 2.0032039642333985
Train loss: 1.8533450067043304
Train loss: 1.781340945850719
Train loss: 1.7409816895212447
Train loss: 1.7136997335097368

Evaluating on train...
Val loss: 2.3527724742889404, Val f1: 0.4369508624076843
Val loss: 1.8915062427520752, Val f1: 0.335970938205719
Val loss: 1.7660747915506363, Val f1: 0.3129088282585144
Val loss: 1.7155162312767722, Val f1: 0.3035283386707306
Val loss: 1.6841193011828832, Val f1: 0.2966456711292267
Val loss: 1.664038566982045, Val f1: 0.29511117935180664

Evaluating on test...
Val loss: 3.126109480857849, Val f1: 0.5497493147850037
Val loss: 2.3528035283088684, Val f1: 0.4100421071052551
Val loss: 2.0942345460255942, Val f1: 0.3596085011959076
Val loss: 1.9627244770526886, Val f1: 0.32940787076950073
filter= [3]drop_first= [0, 1]

starting Epoch 1
Training...
Train loss: 2.5730432271957397
Train loss: 2.0019413948059084
Train loss: 1.8499042689800262
Train loss: 1.7769277637655085
Train loss: 1.733512852873121
Train loss: 1.704298131606158

Evaluating on train...
Val loss: 2.3482373356819153, Val f1: 0.5154948234558105
Val loss: 1.8768401861190795, Val f1: 0.4165351390838623
Val loss: 1.7616301327943802, Val f1: 0.38667032122612
Val loss: 1.7073572440580889, Val f1: 0.3748328387737274
Val loss: 1.6750044226646423, Val f1: 0.3688466250896454
Val loss: 1.653429339913761, Val f1: 0.3637121021747589

Evaluating on test...
Val loss: 3.110748767852783, Val f1: 0.6835460662841797
Val loss: 2.342144191265106, Val f1: 0.5038493275642395
Val loss: 2.0841484864552817, Val f1: 0.4463331699371338
Val loss: 1.9532577991485596, Val f1: 0.41745662689208984
filter= [3]drop_first= [0, 1]

starting Epoch 2
Training...
Train loss: 2.5411409735679626
Train loss: 1.9916614294052124
Train loss: 1.8501054346561432
Train loss: 1.78027897531336
Train loss: 1.7372989569391524
Train loss: 1.7088128398446476

Evaluating on train...
Val loss: 2.346858501434326, Val f1: 0.5938224196434021
Val loss: 1.878411102294922, Val f1: 0.462209552526474
Val loss: 1.7573439627885818, Val f1: 0.43303051590919495
Val loss: 1.7024181539362127, Val f1: 0.4226053059101105
Val loss: 1.6732358421598161, Val f1: 0.41559574007987976
Val loss: 1.6540818354662727, Val f1: 0.41195669770240784

Evaluating on test...
Val loss: 3.108689069747925, Val f1: 0.7805843353271484
Val loss: 2.340165615081787, Val f1: 0.5782318711280823
Val loss: 2.0829771359761557, Val f1: 0.5115624070167542
Val loss: 1.9513077139854431, Val f1: 0.4833221733570099
new best_f1 reached
filter= [3]drop_first= [0, 1]

starting Epoch 3
Training...
Train loss: 2.582287609577179
Train loss: 2.000885820388794
Train loss: 1.8573990762233734
Train loss: 1.7896666743538596
Train loss: 1.7487786241940089
Train loss: 1.7203779991935282

Evaluating on train...
Val loss: 2.379518210887909, Val f1: 0.5202486515045166
Val loss: 1.9069007396698, Val f1: 0.4129059910774231
Val loss: 1.7856718301773071, Val f1: 0.38824519515037537
Val loss: 1.734028935432434, Val f1: 0.3731621503829956
Val loss: 1.7054529275212968, Val f1: 0.3634326159954071
Val loss: 1.6853977862526388, Val f1: 0.3609340190887451

Evaluating on test...
Val loss: 3.1758646965026855, Val f1: 0.6696977615356445
Val loss: 2.388647735118866, Val f1: 0.49804332852363586
Val loss: 2.1273077726364136, Val f1: 0.4405052959918976
Val loss: 1.991981565952301, Val f1: 0.41786012053489685
filter= [3]drop_first= [0, 1]

starting Epoch 4
Training...
Train loss: 2.5431660413742065
Train loss: 1.9817565202713012
Train loss: 1.8388603776693344
Train loss: 1.7735261917114258
Train loss: 1.7350493158612932
Train loss: 1.71057488637812

Evaluating on train...
Val loss: 2.359584152698517, Val f1: 0.44001415371894836
Val loss: 1.886911964416504, Val f1: 0.3640482723712921
Val loss: 1.773245319724083, Val f1: 0.3341980278491974
Val loss: 1.7206341244957664, Val f1: 0.32207971811294556
Val loss: 1.6925677401678902, Val f1: 0.3141884207725525
Val loss: 1.6721461239983053, Val f1: 0.3098275661468506

Evaluating on test...
Val loss: 3.1417930126190186, Val f1: 0.5807405710220337
Val loss: 2.364379048347473, Val f1: 0.4309232831001282
Val loss: 2.105032444000244, Val f1: 0.378667950630188
Val loss: 1.9728513360023499, Val f1: 0.34818315505981445
filter= [3]drop_first= [0, 1]

starting Epoch 0
Training...
Train loss: 2.5470961928367615
Train loss: 1.986795973777771
Train loss: 1.8461130112409592
Train loss: 1.7782416343688965
Train loss: 1.737977819783347
Train loss: 1.71271910386927

Evaluating on train...
Val loss: 2.366825759410858, Val f1: 0.5200505256652832
Val loss: 1.8918352365493774, Val f1: 0.4186423420906067
Val loss: 1.7738618850708008, Val f1: 0.3939356803894043
Val loss: 1.7233606685291638, Val f1: 0.37705719470977783
Val loss: 1.6930619989122664, Val f1: 0.3704330623149872
Val loss: 1.6730722749934477, Val f1: 0.36305874586105347

Evaluating on test...
Val loss: 3.1516952514648438, Val f1: 0.6730856895446777
Val loss: 2.3714001774787903, Val f1: 0.49918806552886963
Val loss: 2.1113109588623047, Val f1: 0.44268831610679626
Val loss: 1.9772651493549347, Val f1: 0.41947752237319946
filter= [3]drop_first= [0, 1]

starting Epoch 1
Training...
Train loss: 2.569380760192871
Train loss: 1.9973070859909057
Train loss: 1.851923018693924
Train loss: 1.7830652865496548
Train loss: 1.7403497099876404
Train loss: 1.712576704866746

Evaluating on train...
Val loss: 2.388372242450714, Val f1: 0.4794897735118866
Val loss: 1.906344962120056, Val f1: 0.3982495665550232
Val loss: 1.7817525416612625, Val f1: 0.3785381019115448
Val loss: 1.7263530167666348, Val f1: 0.3661551773548126
Val loss: 1.6954858217920576, Val f1: 0.3627524673938751
Val loss: 1.6756111173068775, Val f1: 0.357088565826416

Evaluating on test...
Val loss: 3.148244619369507, Val f1: 0.652170717716217
Val loss: 2.368735909461975, Val f1: 0.4873756766319275
Val loss: 2.109073599179586, Val f1: 0.4322855472564697
Val loss: 1.9755773544311523, Val f1: 0.40218687057495117
filter= [3]drop_first= [0, 1]

starting Epoch 2
Training...
Train loss: 2.5477185249328613
Train loss: 1.9834484815597535
Train loss: 1.8431805074214935
Train loss: 1.7771591489965266
Train loss: 1.7360628247261047
Train loss: 1.7120236298617195

Evaluating on train...
Val loss: 2.3556092381477356, Val f1: 0.4934459626674652
Val loss: 1.8838330507278442, Val f1: 0.3996792435646057
Val loss: 1.7633115649223328, Val f1: 0.3824463188648224
Val loss: 1.7145019878040662, Val f1: 0.3625589609146118
Val loss: 1.6817624824387687, Val f1: 0.35728737711906433
Val loss: 1.6621916855082792, Val f1: 0.3507680296897888

Evaluating on test...
Val loss: 3.1238971948623657, Val f1: 0.6652406454086304
Val loss: 2.3518728613853455, Val f1: 0.4893367290496826
Val loss: 2.0939458211263022, Val f1: 0.43026280403137207
Val loss: 1.961935043334961, Val f1: 0.40109097957611084
filter= [3]drop_first= [0, 1]

starting Epoch 3
Training...
Train loss: 2.5427843928337097
Train loss: 1.9837979316711425
Train loss: 1.8450246155261993
Train loss: 1.77661010352048
Train loss: 1.7342049734933036
Train loss: 1.7070794596391565

Evaluating on train...
Val loss: 2.341779053211212, Val f1: 0.5259954333305359
Val loss: 1.8836774349212646, Val f1: 0.40728920698165894
Val loss: 1.7626998126506805, Val f1: 0.3836098909378052
Val loss: 1.7115867896513506, Val f1: 0.3756747245788574
Val loss: 1.6831761172839574, Val f1: 0.36682388186454773
Val loss: 1.66034155032214, Val f1: 0.3654337227344513

Evaluating on test...
Val loss: 3.1248759031295776, Val f1: 0.6801643967628479
Val loss: 2.352956235408783, Val f1: 0.5016282796859741
Val loss: 2.095033804575602, Val f1: 0.4458465278148651
Val loss: 1.9625702798366547, Val f1: 0.42205849289894104
filter= [3]drop_first= [0, 1]

starting Epoch 4
Training...
Train loss: 2.552199959754944
Train loss: 1.991023850440979
Train loss: 1.8460923731327057
Train loss: 1.7788517800244419
Train loss: 1.7406009946550642
Train loss: 1.7152924046796911

Evaluating on train...
Val loss: 2.3980419039726257, Val f1: 0.49195021390914917
Val loss: 1.9110402822494508, Val f1: 0.40314561128616333
Val loss: 1.790759563446045, Val f1: 0.38075581192970276
Val loss: 1.7298915928060359, Val f1: 0.37133920192718506
Val loss: 1.6984741176877702, Val f1: 0.36670535802841187
Val loss: 1.680039405822754, Val f1: 0.36411452293395996

Evaluating on test...
Val loss: 3.1610913276672363, Val f1: 0.6775422096252441
Val loss: 2.378411293029785, Val f1: 0.5029220581054688
Val loss: 2.1177978515625, Val f1: 0.44679000973701477
Val loss: 1.983344554901123, Val f1: 0.4232308864593506
