{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Копия блокнота \"NN_HW3.ipynb\"",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install ipdb"
      ],
      "metadata": {
        "id": "6gnva_Jk4cp-",
        "outputId": "09bcc934-e61d-4af8-8347-64106be93d3e",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:34:36.252973Z",
          "iopub.execute_input": "2021-12-21T15:34:36.253506Z",
          "iopub.status.idle": "2021-12-21T15:34:49.228510Z",
          "shell.execute_reply.started": "2021-12-21T15:34:36.253394Z",
          "shell.execute_reply": "2021-12-21T15:34:49.227818Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.7/dist-packages (0.13.9)\n",
            "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from ipdb) (0.10.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (57.4.0)\n",
            "Requirement already satisfied: ipython>=7.17.0 in /usr/local/lib/python3.7/dist-packages (from ipdb) (7.30.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (3.0.24)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.18.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.17.0->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchmetrics"
      ],
      "metadata": {
        "id": "rjD0eBJtR7Bu",
        "outputId": "80f3dc24-7731-4538-c6ce-8d9e09298dfe",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:34:49.231249Z",
          "iopub.execute_input": "2021-12-21T15:34:49.231476Z",
          "iopub.status.idle": "2021-12-21T15:34:57.495072Z",
          "shell.execute_reply.started": "2021-12-21T15:34:49.231452Z",
          "shell.execute_reply": "2021-12-21T15:34:57.494183Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/tn6x5f4ybaj34zf/Fake.csv?dl=0 -O data.csv"
      ],
      "metadata": {
        "id": "9aY0ptGa94aY",
        "outputId": "d2d51aac-fc2d-4c3c-852a-18098152790a",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:34:57.496489Z",
          "iopub.execute_input": "2021-12-21T15:34:57.496729Z",
          "iopub.status.idle": "2021-12-21T15:35:05.918890Z",
          "shell.execute_reply.started": "2021-12-21T15:34:57.496701Z",
          "shell.execute_reply": "2021-12-21T15:35:05.918044Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 19:00:30--  https://www.dropbox.com/s/tn6x5f4ybaj34zf/Fake.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6030:18::a27d:5012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/tn6x5f4ybaj34zf/Fake.csv [following]\n",
            "--2021-12-21 19:00:30--  https://www.dropbox.com/s/raw/tn6x5f4ybaj34zf/Fake.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf96c171f0c6b328c105cee58ff.dl.dropboxusercontent.com/cd/0/inline/BcRV-L1X6LoWDfH6L4Lpz6PYrXOax-PtWXfJeTTGNY1qT4PW-QmU3ZlDTrcJ9xJbMQTqh3xlc4RFk5npMpCpXT-rnWTVN-LAVCQlJXKFpiQEdrWaDpTJ1JdLF9hxlp8MvWogAaW1xm8E321d8J-bhhuo/file# [following]\n",
            "--2021-12-21 19:00:31--  https://ucf96c171f0c6b328c105cee58ff.dl.dropboxusercontent.com/cd/0/inline/BcRV-L1X6LoWDfH6L4Lpz6PYrXOax-PtWXfJeTTGNY1qT4PW-QmU3ZlDTrcJ9xJbMQTqh3xlc4RFk5npMpCpXT-rnWTVN-LAVCQlJXKFpiQEdrWaDpTJ1JdLF9hxlp8MvWogAaW1xm8E321d8J-bhhuo/file\n",
            "Resolving ucf96c171f0c6b328c105cee58ff.dl.dropboxusercontent.com (ucf96c171f0c6b328c105cee58ff.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to ucf96c171f0c6b328c105cee58ff.dl.dropboxusercontent.com (ucf96c171f0c6b328c105cee58ff.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62789876 (60M) [text/plain]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv            100%[===================>]  59.88M   106MB/s    in 0.6s    \n",
            "\n",
            "2021-12-21 19:00:32 (106 MB/s) - ‘data.csv’ saved [62789876/62789876]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "import ipdb\n",
        "\n",
        "import re\n",
        "import torchmetrics\n",
        "from torchmetrics import F1\n",
        "from torchmetrics.functional import f1, recall\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8-k_Aft6RwCK",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:05.921227Z",
          "iopub.execute_input": "2021-12-21T15:35:05.923553Z",
          "iopub.status.idle": "2021-12-21T15:35:08.764339Z",
          "shell.execute_reply.started": "2021-12-21T15:35:05.923515Z",
          "shell.execute_reply": "2021-12-21T15:35:08.763434Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "8LcFO32G-CWn",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:08.765674Z",
          "iopub.execute_input": "2021-12-21T15:35:08.765924Z",
          "iopub.status.idle": "2021-12-21T15:35:09.451729Z",
          "shell.execute_reply.started": "2021-12-21T15:35:08.765877Z",
          "shell.execute_reply": "2021-12-21T15:35:09.450628Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "ppZcfgo3P_p0",
        "outputId": "0965d222-1b3b-4d9e-ef0d-b458e044d022",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:09.453196Z",
          "iopub.execute_input": "2021-12-21T15:35:09.453499Z",
          "iopub.status.idle": "2021-12-21T15:35:09.474911Z",
          "shell.execute_reply.started": "2021-12-21T15:35:09.453467Z",
          "shell.execute_reply": "2021-12-21T15:35:09.473926Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d00ba78-7d81-4c7e-86e4-8508b5c30b7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d00ba78-7d81-4c7e-86e4-8508b5c30b7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d00ba78-7d81-4c7e-86e4-8508b5c30b7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d00ba78-7d81-4c7e-86e4-8508b5c30b7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               title  ...               date\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...  ...  December 31, 2017\n",
              "1   Drunk Bragging Trump Staffer Started Russian ...  ...  December 31, 2017\n",
              "2   Sheriff David Clarke Becomes An Internet Joke...  ...  December 30, 2017\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    res = re.sub(r'[^A-z]', ' ', text)\n",
        "    res = res.lower()\n",
        "    return res"
      ],
      "metadata": {
        "id": "llrSBSXS4esr",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:09.476364Z",
          "iopub.execute_input": "2021-12-21T15:35:09.478050Z",
          "iopub.status.idle": "2021-12-21T15:35:09.482077Z",
          "shell.execute_reply.started": "2021-12-21T15:35:09.478010Z",
          "shell.execute_reply": "2021-12-21T15:35:09.481252Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df.text.apply(preprocess)"
      ],
      "metadata": {
        "id": "bK3mfYgZPpcU",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:09.483494Z",
          "iopub.execute_input": "2021-12-21T15:35:09.484225Z",
          "iopub.status.idle": "2021-12-21T15:35:14.553091Z",
          "shell.execute_reply.started": "2021-12-21T15:35:09.484125Z",
          "shell.execute_reply": "2021-12-21T15:35:14.552300Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"subject\"].value_counts()"
      ],
      "metadata": {
        "id": "UuZhjnHaQIwC",
        "outputId": "d2622a27-d4a9-4694-fdb9-6fe0b5015ade",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:14.554347Z",
          "iopub.execute_input": "2021-12-21T15:35:14.555207Z",
          "iopub.status.idle": "2021-12-21T15:35:14.569717Z",
          "shell.execute_reply.started": "2021-12-21T15:35:14.555164Z",
          "shell.execute_reply": "2021-12-21T15:35:14.568832Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "News               9050\n",
              "politics           6841\n",
              "left-news          4459\n",
              "Government News    1570\n",
              "US_News             783\n",
              "Middle-east         778\n",
              "Name: subject, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coded = {\"subject\":     {\"News\": 0, \n",
        "                                \"politics\": 1,\n",
        "                                \"left-news\": 2,\n",
        "                                \"Government News\": 3,\n",
        "                                \"US_News\": 4,\n",
        "                                \"Middle-east\": 5}}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:14.572756Z",
          "iopub.execute_input": "2021-12-21T15:35:14.573427Z",
          "iopub.status.idle": "2021-12-21T15:35:14.580596Z",
          "shell.execute_reply.started": "2021-12-21T15:35:14.573389Z",
          "shell.execute_reply": "2021-12-21T15:35:14.579950Z"
        },
        "trusted": true,
        "id": "fFlfRI2xpl9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace(coded)"
      ],
      "metadata": {
        "id": "AUxH5wKDPnKv",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:14.583879Z",
          "iopub.execute_input": "2021-12-21T15:35:14.585045Z",
          "iopub.status.idle": "2021-12-21T15:35:14.617757Z",
          "shell.execute_reply.started": "2021-12-21T15:35:14.585007Z",
          "shell.execute_reply": "2021-12-21T15:35:14.617048Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "b9ydTwdEGjJB",
        "outputId": "a9fb797c-076b-4182-bb09-bed2bad5d48f",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:14.619026Z",
          "iopub.execute_input": "2021-12-21T15:35:14.619430Z",
          "iopub.status.idle": "2021-12-21T15:35:14.628884Z",
          "shell.execute_reply.started": "2021-12-21T15:35:14.619400Z",
          "shell.execute_reply": "2021-12-21T15:35:14.627968Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-10f24ce1-1b2f-4e99-853d-e7f1494b256f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>donald trump just couldn t wish all americans ...</td>\n",
              "      <td>0</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>house intelligence committee chairman devin nu...</td>\n",
              "      <td>0</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>on friday  it was revealed that former milwauk...</td>\n",
              "      <td>0</td>\n",
              "      <td>December 30, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10f24ce1-1b2f-4e99-853d-e7f1494b256f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10f24ce1-1b2f-4e99-853d-e7f1494b256f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10f24ce1-1b2f-4e99-853d-e7f1494b256f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               title  ...               date\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...  ...  December 31, 2017\n",
              "1   Drunk Bragging Trump Staffer Started Russian ...  ...  December 31, 2017\n",
              "2   Sheriff David Clarke Becomes An Internet Joke...  ...  December 30, 2017\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "t_F8Va0BRQq6",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:14.630195Z",
          "iopub.execute_input": "2021-12-21T15:35:14.630576Z",
          "iopub.status.idle": "2021-12-21T15:35:14.646660Z",
          "shell.execute_reply.started": "2021-12-21T15:35:14.630534Z",
          "shell.execute_reply": "2021-12-21T15:35:14.646097Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for text in df['text']:\n",
        "    text = text.split()\n",
        "    vocab.update(text)\n",
        "#print('всего уникальных токенов:', len(vocab))\n",
        "\n",
        "filtered_vocab = set()\n",
        "for word in vocab:\n",
        "    if vocab[word] > 5:\n",
        "        filtered_vocab.add(word)\n",
        "#print('уникальных токенов, встретившихся больше 5 раз:', len(filtered_vocab))"
      ],
      "metadata": {
        "id": "F7EZLNVURVZM",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:14.647718Z",
          "iopub.execute_input": "2021-12-21T15:35:14.647962Z",
          "iopub.status.idle": "2021-12-21T15:35:16.917258Z",
          "shell.execute_reply.started": "2021-12-21T15:35:14.647932Z",
          "shell.execute_reply": "2021-12-21T15:35:16.916630Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {'PAD':0}\n",
        "\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)\n",
        "\n",
        "#обратный словарь для того, чтобы раскодировать последовательность\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "metadata": {
        "id": "Hb-bZPX-RVbu",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:16.918597Z",
          "iopub.execute_input": "2021-12-21T15:35:16.919034Z",
          "iopub.status.idle": "2021-12-21T15:35:16.943510Z",
          "shell.execute_reply.started": "2021-12-21T15:35:16.918989Z",
          "shell.execute_reply": "2021-12-21T15:35:16.942929Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "id": "dsajyJ6iD1gH",
        "outputId": "2a3e3636-0605-4170-c3e5-80da225b5314",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:16.946052Z",
          "iopub.execute_input": "2021-12-21T15:35:16.946640Z",
          "iopub.status.idle": "2021-12-21T15:35:16.953378Z",
          "shell.execute_reply.started": "2021-12-21T15:35:16.946603Z",
          "shell.execute_reply": "2021-12-21T15:35:16.952586Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, dataset, col, target_col, word2id, max_len, DEVICE):\n",
        "        self.dataset = dataset[col].values\n",
        "        self.word2id = word2id\n",
        "        self.length = dataset.shape[0]\n",
        "        self.target = torch.Tensor(dataset[target_col].values)\n",
        "        self.max_len = max_len\n",
        "        self.device = DEVICE\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index): \n",
        "        tokens = self.dataset[index].split()\n",
        "        ids = torch.LongTensor([self.word2id[token] if token in self.word2id else self.word2id['PAD'] for token in tokens][:self.max_len])\n",
        "        y = [self.target[index]]\n",
        "        return ids, y\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "      ids, y = list(zip(*batch))\n",
        "      padded_ids = torch.vstack([F.pad(seq, pad=(0, self.max_len - seq.shape[0]), mode='constant', value=0) for seq in ids])\n",
        "      padded_ids = pad_sequence(ids, batch_first=True).to(self.device)\n",
        "      y = torch.LongTensor(y).to(self.device)\n",
        "      return padded_ids, y.T[0]"
      ],
      "metadata": {
        "id": "wXI-CTJsPnNL",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:16.955002Z",
          "iopub.execute_input": "2021-12-21T15:35:16.955659Z",
          "iopub.status.idle": "2021-12-21T15:35:16.969865Z",
          "shell.execute_reply.started": "2021-12-21T15:35:16.955622Z",
          "shell.execute_reply": "2021-12-21T15:35:16.969128Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(train_sentences, 'text', 'subject', word2id, 400, DEVICE)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=1024)"
      ],
      "metadata": {
        "id": "FnX3gKIeXM81",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:16.971205Z",
          "iopub.execute_input": "2021-12-21T15:35:16.971598Z",
          "iopub.status.idle": "2021-12-21T15:35:16.998392Z",
          "shell.execute_reply.started": "2021-12-21T15:35:16.971569Z",
          "shell.execute_reply": "2021-12-21T15:35:16.997694Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = Dataset(val_sentences, 'text', 'subject', word2id, 400, DEVICE)\n",
        "val_sampler = SequentialSampler(val_dataset)\n",
        "val_iterator = DataLoader(val_dataset, collate_fn = val_dataset.collate_fn, sampler=val_sampler, batch_size=1024)"
      ],
      "metadata": {
        "id": "C3g-bEuMDBHq",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:16.999671Z",
          "iopub.execute_input": "2021-12-21T15:35:17.000051Z",
          "iopub.status.idle": "2021-12-21T15:35:17.005264Z",
          "shell.execute_reply.started": "2021-12-21T15:35:17.000007Z",
          "shell.execute_reply": "2021-12-21T15:35:17.004496Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "metadata": {
        "id": "gZmwnjcVQ5kj",
        "outputId": "0ec7bf0a-955a-4a52-bee1-e13142e7a356",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:35:17.006548Z",
          "iopub.execute_input": "2021-12-21T15:35:17.006800Z",
          "iopub.status.idle": "2021-12-21T15:37:18.613062Z",
          "shell.execute_reply.started": "2021-12-21T15:35:17.006770Z",
          "shell.execute_reply": "2021-12-21T15:37:18.612223Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-21 19:00:53--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.46.110\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.46.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "w2v = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)"
      ],
      "metadata": {
        "id": "4TlCdg3vU2j4",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:37:18.614875Z",
          "iopub.execute_input": "2021-12-21T15:37:18.615494Z",
          "iopub.status.idle": "2021-12-21T15:38:33.565346Z",
          "shell.execute_reply.started": "2021-12-21T15:37:18.615447Z",
          "shell.execute_reply": "2021-12-21T15:38:33.564419Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.zeros((len(word2id), 300))\n",
        "\n",
        "for word, i in word2id.items():\n",
        "    try:\n",
        "        weights[i] = w2v[word]\n",
        "    except KeyError:\n",
        "        weights[i] = np.random.uniform(-0.25, 0.25, 300)\n",
        "\n",
        "weights = torch.FloatTensor(weights)"
      ],
      "metadata": {
        "id": "YlFOqXd0U2nS",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:38:33.566722Z",
          "iopub.execute_input": "2021-12-21T15:38:33.566976Z",
          "iopub.status.idle": "2021-12-21T15:38:33.855863Z",
          "shell.execute_reply.started": "2021-12-21T15:38:33.566946Z",
          "shell.execute_reply": "2021-12-21T15:38:33.855211Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Использовала код на tensorflow отсюда: https://github.com/KifayatMsd/C-LSTM-text-classification/blob/master/clstm_classifier.py"
      ],
      "metadata": {
        "id": "mmBHXVVvuxI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class clstm_clf(nn.Module):\n",
        "  def __init__(self, max_length, vocab_size, filter_list, drop_first):\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.filter_list = filter_list\n",
        "    self.drop_first = drop_first\n",
        "    self.max_length = max_length\n",
        "    \n",
        "    self.embedding = nn.Embedding(vocab_size, 300)\n",
        "    self.embedding.from_pretrained(torch.tensor(weights))\n",
        "    \n",
        "    self.conv2 = nn.Conv1d(in_channels=300, out_channels=150, kernel_size=2)\n",
        "    self.conv3 = nn.Conv1d(in_channels=300, out_channels=150, kernel_size=3)\n",
        "    self.conv4 = nn.Conv1d(in_channels=300, out_channels=150, kernel_size=4)\n",
        "\n",
        "    self.convs = [self.conv2, self.conv3, self.conv4]\n",
        "    \n",
        "    self.lstm = nn.LSTM(input_size=150, hidden_size=150, num_layers=1, batch_first=True)\n",
        "    self.dropout = nn.Dropout(p=0.5)            \n",
        "    self.relu = nn.ReLU()\n",
        "    self.out = nn.Softmax(dim=1)\n",
        "    self.linear = nn.Linear(150, 6)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.dropout(self.embedding(text)).transpose(1, 2)\n",
        "    max_len = self.max_length - max(self.filter_list) + 1\n",
        "    \n",
        "    outputs = []\n",
        "    for item in range(2):\n",
        "      layer = self.convs[item](embedded)\n",
        "      hid = self.relu(layer)[:, :, :max_len]\n",
        "      outputs.append(hid)\n",
        "\n",
        "    if len(self.filter_list) > 1:\n",
        "      rnn_inputs = torch.cat(outputs, -1)\n",
        "    else:\n",
        "      rnn_inputs = hid\n",
        "\n",
        "    _, (hidden_state, _) = self.lstm(rnn_inputs.transpose(1, 2))\n",
        "    if self.drop_first:\n",
        "      embedded = self.dropout(embedded)\n",
        "    logits = self.out(self.linear(torch.squeeze(hidden_state, 0)))\n",
        "        \n",
        "    return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-21T15:38:33.857530Z",
          "iopub.execute_input": "2021-12-21T15:38:33.858116Z",
          "iopub.status.idle": "2021-12-21T15:38:33.925611Z",
          "shell.execute_reply.started": "2021-12-21T15:38:33.858057Z",
          "shell.execute_reply": "2021-12-21T15:38:33.924488Z"
        },
        "trusted": true,
        "id": "6ploz_mDpl9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0 # для подсчета среднего лосса на всех батчах\n",
        "\n",
        "    model.train()  # ставим модель в обучение, явно указываем, что сейчас надо будет хранить градиенты у всех весов\n",
        "\n",
        "    for i, (texts, ys) in enumerate(iterator): #итерируемся по батчам\n",
        "        optimizer.zero_grad()  #обнуляем градиенты\n",
        "        preds = model(texts)  #прогоняем данные через модель\n",
        "        loss = criterion(preds, ys) #считаем значение функции потерь  \n",
        "        loss.backward() #считаем градиенты  \n",
        "        optimizer.step() #обновляем веса \n",
        "        epoch_loss += loss.item() #сохраняем значение функции потерь\n",
        "        if not (i + 1) % int(len(iterator)/5):\n",
        "            print(f'Train loss: {epoch_loss/i}')      \n",
        "    return  epoch_loss / len(iterator) # возвращаем среднее значение лосса по всей выборке"
      ],
      "metadata": {
        "id": "aRHg5Gw0W30q",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:38:33.927299Z",
          "iopub.execute_input": "2021-12-21T15:38:33.927619Z",
          "iopub.status.idle": "2021-12-21T15:38:33.938500Z",
          "shell.execute_reply.started": "2021-12-21T15:38:33.927581Z",
          "shell.execute_reply": "2021-12-21T15:38:33.937569Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_metric = 0\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        for i, (texts, ys) in enumerate(iterator):   \n",
        "            preds = model(texts)  # делаем предсказания на тесте\n",
        "            loss = criterion(preds, ys)   # считаем значения функции ошибки для статистики  \n",
        "            epoch_loss += loss.item()\n",
        "            batch_metric = f1(preds.argmax(1).long(), ys.long(), ignore_index=0)\n",
        "            epoch_metric += batch_metric\n",
        "            if i != 0:\n",
        "                if not (i + 1) % int(len(iterator)/5):\n",
        "                  #print(f'длина итератора: ', len(iterator))\n",
        "                  print(f'Val loss: {epoch_loss/i}, Val f1: {epoch_metric/i}')\n",
        "        \n",
        "    return epoch_metric / len(iterator), epoch_loss / len(iterator) # возвращаем среднее значение по всей выборке"
      ],
      "metadata": {
        "id": "HdUNzMX3W34O",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:38:33.940119Z",
          "iopub.execute_input": "2021-12-21T15:38:33.941249Z",
          "iopub.status.idle": "2021-12-21T15:38:33.953745Z",
          "shell.execute_reply.started": "2021-12-21T15:38:33.941210Z",
          "shell.execute_reply": "2021-12-21T15:38:33.953125Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning(n_epochs, model, optimizer, criterion):\n",
        "    for i in range(n_epochs):\n",
        "        print(f'\\nstarting Epoch {i}')\n",
        "        print('Training...')\n",
        "        epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
        "        losses.append(epoch_loss)\n",
        "        print('\\nEvaluating on train...')\n",
        "        f1_on_train,_ = evaluate(model, train_iterator, criterion)\n",
        "        f1s.append(f1_on_train.cpu())\n",
        "        print('\\nEvaluating on test...')\n",
        "        f1_on_test, epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
        "        losses_eval.append(epoch_loss_on_test)\n",
        "        f1s_eval.append(f1_on_test.cpu())"
      ],
      "metadata": {
        "id": "8OInb2In1M-9",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:38:33.955018Z",
          "iopub.execute_input": "2021-12-21T15:38:33.955766Z",
          "iopub.status.idle": "2021-12-21T15:38:33.969214Z",
          "shell.execute_reply.started": "2021-12-21T15:38:33.955720Z",
          "shell.execute_reply": "2021-12-21T15:38:33.968413Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = clstm_clf(max_length=400, vocab_size=len(word2id), filter_list=[2], drop_first=0)\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion(torch.tensor([0.45, 0.22, 0.32]).unsqueeze(1).unsqueeze(0), torch.tensor([1]).unsqueeze(0).long())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-21T15:38:33.971367Z",
          "iopub.execute_input": "2021-12-21T15:38:33.971703Z",
          "iopub.status.idle": "2021-12-21T15:38:34.179383Z",
          "shell.execute_reply.started": "2021-12-21T15:38:33.971659Z",
          "shell.execute_reply": "2021-12-21T15:38:34.178439Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU2sQCSdpl9j",
        "outputId": "77169f4f-8f5c-4b9f-824a-a22680315c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.2131)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "losses_eval = []\n",
        "f1s = []\n",
        "f1s_eval = []\n",
        "\n",
        "for i in range(5):\n",
        "    print(f'\\nstarting Epoch {i}')\n",
        "    print('Training...')\n",
        "    epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
        "    losses.append(epoch_loss)\n",
        "    print('\\nEvaluating on train...')\n",
        "    f1_on_train,_ = evaluate(model, train_iterator, criterion)\n",
        "    f1s.append(f1_on_train)\n",
        "    print('\\nEvaluating on test...')\n",
        "    f1_on_test, epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
        "    losses_eval.append(epoch_loss_on_test)\n",
        "    f1s_eval.append(f1_on_test)"
      ],
      "metadata": {
        "id": "ZnQXEd_o1NBO",
        "outputId": "dfed0852-a24c-4218-ce73-cfbc00146971",
        "execution": {
          "iopub.status.busy": "2021-12-21T15:38:34.183209Z",
          "iopub.execute_input": "2021-12-21T15:38:34.183430Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "starting Epoch 0\n",
            "Training...\n",
            "Train loss: 2.5594388246536255\n",
            "Train loss: 1.9927241563796998\n",
            "Train loss: 1.8491605669260025\n",
            "Train loss: 1.7833099473606457\n",
            "Train loss: 1.743791128907885\n",
            "Train loss: 1.7152950553333057\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.387777268886566, Val f1: 0.4892374873161316\n",
            "Val loss: 1.9026559352874757, Val f1: 0.4086170792579651\n",
            "Val loss: 1.7811417132616043, Val f1: 0.3916016221046448\n",
            "Val loss: 1.7243535843762485, Val f1: 0.38272663950920105\n",
            "Val loss: 1.6944471427372523, Val f1: 0.37336573004722595\n",
            "Val loss: 1.6767759112750782, Val f1: 0.3681832551956177\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.1698328256607056, Val f1: 0.6833368539810181\n",
            "Val loss: 2.368855595588684, Val f1: 0.5224043726921082\n",
            "Val loss: 2.1087040106455484, Val f1: 0.4624018371105194\n",
            "Val loss: 1.9774484038352966, Val f1: 0.4454635679721832\n",
            "\n",
            "starting Epoch 1\n",
            "Training...\n",
            "Train loss: 2.383388638496399\n",
            "Train loss: 1.9028599262237549\n",
            "Train loss: 1.77252858877182\n",
            "Train loss: 1.71653705293482\n",
            "Train loss: 1.6783022965703691\n",
            "Train loss: 1.6455104491289925\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.252649247646332, Val f1: 0.5796581506729126\n",
            "Val loss: 1.7944404840469361, Val f1: 0.47863444685935974\n",
            "Val loss: 1.6927181482315063, Val f1: 0.4342324137687683\n",
            "Val loss: 1.6414193348451094, Val f1: 0.42127564549446106\n",
            "Val loss: 1.6132148333958216, Val f1: 0.4146503508090973\n",
            "Val loss: 1.5943017146166634, Val f1: 0.41120171546936035\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.0072590112686157, Val f1: 0.7821494340896606\n",
            "Val loss: 2.25003844499588, Val f1: 0.5855737328529358\n",
            "Val loss: 2.002722978591919, Val f1: 0.5209100842475891\n",
            "Val loss: 1.8776130676269531, Val f1: 0.49643686413764954\n",
            "\n",
            "starting Epoch 2\n",
            "Training...\n",
            "Train loss: 2.2471062541007996\n",
            "Train loss: 1.792675828933716\n",
            "Train loss: 1.676458477973938\n",
            "Train loss: 1.6210969903252341\n",
            "Train loss: 1.5879874399730138\n",
            "Train loss: 1.5688048180411844\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.2059279680252075, Val f1: 0.6019783616065979\n",
            "Val loss: 1.761948251724243, Val f1: 0.4789663851261139\n",
            "Val loss: 1.653851494193077, Val f1: 0.4383445382118225\n",
            "Val loss: 1.6038651791485874, Val f1: 0.42179611325263977\n",
            "Val loss: 1.5747501679829188, Val f1: 0.41403868794441223\n",
            "Val loss: 1.5552284296821146, Val f1: 0.4132876396179199\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 2.9301884174346924, Val f1: 0.7923246622085571\n",
            "Val loss: 2.1911308765411377, Val f1: 0.5939534902572632\n",
            "Val loss: 1.951014240582784, Val f1: 0.526553213596344\n",
            "Val loss: 1.8294630348682404, Val f1: 0.5014331936836243\n",
            "\n",
            "starting Epoch 3\n",
            "Training...\n",
            "Train loss: 2.2068174481391907\n",
            "Train loss: 1.7549435138702392\n",
            "Train loss: 1.6535343080759048\n",
            "Train loss: 1.5992486802014438\n",
            "Train loss: 1.5709287013326372\n",
            "Train loss: 1.5524037936154533\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.196456789970398, Val f1: 0.6409258246421814\n",
            "Val loss: 1.7486071109771728, Val f1: 0.5067262649536133\n",
            "Val loss: 1.6441982686519623, Val f1: 0.46448928117752075\n",
            "Val loss: 1.5945833379572087, Val f1: 0.44878149032592773\n",
            "Val loss: 1.57296108348029, Val f1: 0.43142151832580566\n",
            "Val loss: 1.5548024738536161, Val f1: 0.42608973383903503\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 2.9426380395889282, Val f1: 0.80677330493927\n",
            "Val loss: 2.202091634273529, Val f1: 0.6060381531715393\n",
            "Val loss: 1.9600346088409424, Val f1: 0.5372403264045715\n",
            "Val loss: 1.839597225189209, Val f1: 0.5057618618011475\n",
            "\n",
            "starting Epoch 4\n",
            "Training...\n",
            "Train loss: 2.1890458464622498\n",
            "Train loss: 1.76048743724823\n",
            "Train loss: 1.6528756320476532\n",
            "Train loss: 1.5988261374560269\n",
            "Train loss: 1.5695428677967616\n",
            "Train loss: 1.5497399358188404\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.174642860889435, Val f1: 0.6272145509719849\n",
            "Val loss: 1.7431467771530151, Val f1: 0.496612548828125\n",
            "Val loss: 1.6398364305496216, Val f1: 0.453896164894104\n",
            "Val loss: 1.588520418513905, Val f1: 0.4403686821460724\n",
            "Val loss: 1.5609835726874215, Val f1: 0.4304409325122833\n",
            "Val loss: 1.5427742986118091, Val f1: 0.42624735832214355\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 2.9204922914505005, Val f1: 0.7984296679496765\n",
            "Val loss: 2.184318959712982, Val f1: 0.5984297394752502\n",
            "Val loss: 1.9451059897740681, Val f1: 0.5311845541000366\n",
            "Val loss: 1.8257038593292236, Val f1: 0.5033267140388489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Подбор гиперпараметров"
      ],
      "metadata": {
        "id": "g9leTKUFOrPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filters = [[2], [3]]\n",
        "drop_first = [0, 1]\n",
        "best_f1 = 0\n",
        "\n",
        "for filter in filters:\n",
        "  for d in drop_first:\n",
        "    losses_2 = []\n",
        "    losses_eval_2 = []\n",
        "    f1s_2 = []\n",
        "    f1s_eval_2 = []\n",
        "    for i in range(5):\n",
        "        print('filter= ' + str(filter) + 'drop_first= ' + str(drop_first))\n",
        "        model = clstm_clf(max_length=400, vocab_size=len(word2id), filter_list=filter, drop_first=d)\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        print(f'\\nstarting Epoch {i}')\n",
        "        print('Training...')\n",
        "        epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
        "        losses_2.append(epoch_loss)\n",
        "        print('\\nEvaluating on train...')\n",
        "        f1_on_train,_ = evaluate(model, train_iterator, criterion)\n",
        "        f1s_2.append(f1_on_train)\n",
        "        print('\\nEvaluating on test...')\n",
        "        f1_on_test, epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
        "        losses_eval.append(epoch_loss_on_test)\n",
        "        f1s_eval_2.append(f1_on_test)\n",
        "        if f1_on_test > best_f1:\n",
        "          best_f1 = f1_on_test\n",
        "          print('new best_f1 reached')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9OBlYwRLRsX",
        "outputId": "c800b94a-ce0e-4ea9-f309-21e3f9322b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 0\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 2.549215853214264\n",
            "Train loss: 1.9836703777313232\n",
            "Train loss: 1.8406722694635391\n",
            "Train loss: 1.7743672782724553\n",
            "Train loss: 1.7318350076675415\n",
            "Train loss: 1.7007288231569178\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.3070261478424072, Val f1: 0.5190930366516113\n",
            "Val loss: 1.857517671585083, Val f1: 0.4053433835506439\n",
            "Val loss: 1.7475942373275757, Val f1: 0.3756532669067383\n",
            "Val loss: 1.6959430629556829, Val f1: 0.363542377948761\n",
            "Val loss: 1.6660035167421614, Val f1: 0.3606052100658417\n",
            "Val loss: 1.6481268756529863, Val f1: 0.352705717086792\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.1136282682418823, Val f1: 0.6720314025878906\n",
            "Val loss: 2.3253596425056458, Val f1: 0.5072864294052124\n",
            "Val loss: 2.0706846714019775, Val f1: 0.4471189081668854\n",
            "Val loss: 1.9413730204105377, Val f1: 0.4301667809486389\n",
            "new best_f1 reached\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 1\n",
            "Training...\n",
            "Train loss: 2.560003697872162\n",
            "Train loss: 1.9981701135635377\n",
            "Train loss: 1.8577937930822372\n",
            "Train loss: 1.7865707007321445\n",
            "Train loss: 1.7459353038242884\n",
            "Train loss: 1.7187553994795854\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.358573853969574, Val f1: 0.004611487500369549\n",
            "Val loss: 1.88945734500885, Val f1: 0.0055693769827485085\n",
            "Val loss: 1.7699631750583649, Val f1: 0.007410415448248386\n",
            "Val loss: 1.7153734835711392, Val f1: 0.009114102460443974\n",
            "Val loss: 1.6835249151502336, Val f1: 0.00784099381417036\n",
            "Val loss: 1.6648844901253195, Val f1: 0.007569320034235716\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.143706798553467, Val f1: 0.018982309848070145\n",
            "Val loss: 2.3485289812088013, Val f1: 0.011149529367685318\n",
            "Val loss: 2.090878208478292, Val f1: 0.008474686183035374\n",
            "Val loss: 1.9629056453704834, Val f1: 0.007668350823223591\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 2\n",
            "Training...\n",
            "Train loss: 2.551094651222229\n",
            "Train loss: 1.9897008180618285\n",
            "Train loss: 1.8431815803050995\n",
            "Train loss: 1.7797140208157627\n",
            "Train loss: 1.738417046410697\n",
            "Train loss: 1.7140537570504581\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.3732652068138123, Val f1: 0.5797222256660461\n",
            "Val loss: 1.893244695663452, Val f1: 0.4709678292274475\n",
            "Val loss: 1.775928109884262, Val f1: 0.43652650713920593\n",
            "Val loss: 1.723989952694286, Val f1: 0.4277932941913605\n",
            "Val loss: 1.697131676333291, Val f1: 0.41846567392349243\n",
            "Val loss: 1.6795179493287031, Val f1: 0.41037169098854065\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.175097942352295, Val f1: 0.7869569063186646\n",
            "Val loss: 2.3743993043899536, Val f1: 0.5896936058998108\n",
            "Val loss: 2.11292556921641, Val f1: 0.523104190826416\n",
            "Val loss: 1.9811300933361053, Val f1: 0.49834078550338745\n",
            "new best_f1 reached\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 3\n",
            "Training...\n",
            "Train loss: 2.550422489643097\n",
            "Train loss: 1.9943693161010743\n",
            "Train loss: 1.8428440541028976\n",
            "Train loss: 1.7815146121111782\n",
            "Train loss: 1.7434335691588265\n",
            "Train loss: 1.7168613321640913\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.3867432475090027, Val f1: 0.12265124917030334\n",
            "Val loss: 1.9102580308914185, Val f1: 0.08286148309707642\n",
            "Val loss: 1.7925201058387756, Val f1: 0.07765473425388336\n",
            "Val loss: 1.736279617656361, Val f1: 0.07735682278871536\n",
            "Val loss: 1.7046211106436593, Val f1: 0.07316885143518448\n",
            "Val loss: 1.6821572149501127, Val f1: 0.07333219796419144\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.17779803276062, Val f1: 0.13648933172225952\n",
            "Val loss: 2.3727526664733887, Val f1: 0.09826046228408813\n",
            "Val loss: 2.113088607788086, Val f1: 0.09193869680166245\n",
            "Val loss: 1.9827885925769806, Val f1: 0.0887071043252945\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 4\n",
            "Training...\n",
            "Train loss: 2.532183051109314\n",
            "Train loss: 1.9838966846466064\n",
            "Train loss: 1.839351400732994\n",
            "Train loss: 1.7774663296612827\n",
            "Train loss: 1.73647221497127\n",
            "Train loss: 1.7093818257836735\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.3728504180908203, Val f1: 0.541773796081543\n",
            "Val loss: 1.8987592458724976, Val f1: 0.4292631149291992\n",
            "Val loss: 1.7732440382242203, Val f1: 0.41593217849731445\n",
            "Val loss: 1.7210808017037131, Val f1: 0.4016251266002655\n",
            "Val loss: 1.6881436535290308, Val f1: 0.3944290578365326\n",
            "Val loss: 1.6688341954175163, Val f1: 0.38934651017189026\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.1521438360214233, Val f1: 0.7359132170677185\n",
            "Val loss: 2.3550513982772827, Val f1: 0.5550731420516968\n",
            "Val loss: 2.096914013226827, Val f1: 0.49445971846580505\n",
            "Val loss: 1.9662254750728607, Val f1: 0.47229406237602234\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 0\n",
            "Training...\n",
            "Train loss: 2.5438894629478455\n",
            "Train loss: 1.9908328771591186\n",
            "Train loss: 1.8462731838226318\n",
            "Train loss: 1.7819574204358188\n",
            "Train loss: 1.742010201726641\n",
            "Train loss: 1.7142282233518713\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.360115885734558, Val f1: 0.441717267036438\n",
            "Val loss: 1.8895605087280274, Val f1: 0.35741063952445984\n",
            "Val loss: 1.770961955189705, Val f1: 0.33905860781669617\n",
            "Val loss: 1.7149797027761287, Val f1: 0.3304770290851593\n",
            "Val loss: 1.6854261755943298, Val f1: 0.3227415382862091\n",
            "Val loss: 1.6663313543095308, Val f1: 0.3188793957233429\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.1506677865982056, Val f1: 0.6167895793914795\n",
            "Val loss: 2.352638363838196, Val f1: 0.46994203329086304\n",
            "Val loss: 2.0945991675059, Val f1: 0.4132947027683258\n",
            "Val loss: 1.9634458422660828, Val f1: 0.39731505513191223\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 1\n",
            "Training...\n",
            "Train loss: 2.5660125017166138\n",
            "Train loss: 1.9923209190368651\n",
            "Train loss: 1.851325586438179\n",
            "Train loss: 1.7882852445949207\n",
            "Train loss: 1.7473516293934412\n",
            "Train loss: 1.7196229415781357\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.3984004259109497, Val f1: 0.5187161564826965\n",
            "Val loss: 1.9226323366165161, Val f1: 0.41743379831314087\n",
            "Val loss: 1.8015050739049911, Val f1: 0.39237019419670105\n",
            "Val loss: 1.7489153796976262, Val f1: 0.37436506152153015\n",
            "Val loss: 1.7181471075330461, Val f1: 0.3638126254081726\n",
            "Val loss: 1.6975417698130888, Val f1: 0.3577432632446289\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.2156193256378174, Val f1: 0.6776145696640015\n",
            "Val loss: 2.4057443141937256, Val f1: 0.5056151151657104\n",
            "Val loss: 2.1403186321258545, Val f1: 0.4502438008785248\n",
            "Val loss: 2.004895806312561, Val f1: 0.4307863116264343\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 2\n",
            "Training...\n",
            "Train loss: 2.567953109741211\n",
            "Train loss: 1.9894388914108276\n",
            "Train loss: 1.8481678664684296\n",
            "Train loss: 1.7864771322770552\n",
            "Train loss: 1.748206845351628\n",
            "Train loss: 1.7210617486168356\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 2.4195995330810547, Val f1: 0.08961683511734009\n",
            "Val loss: 1.9298482656478881, Val f1: 0.07413512468338013\n",
            "Val loss: 1.8093694746494293, Val f1: 0.07400579005479813\n",
            "Val loss: 1.7546817931261929, Val f1: 0.06829599291086197\n",
            "Val loss: 1.7225043858800615, Val f1: 0.07058040052652359\n",
            "Val loss: 1.7023111371433033, Val f1: 0.06952780485153198\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 3.2180827856063843, Val f1: 0.12768419086933136\n",
            "Val loss: 2.403674840927124, Val f1: 0.09385789185762405\n",
            "Val loss: 2.1401267449061074, Val f1: 0.0861707404255867\n",
            "Val loss: 2.008487820625305, Val f1: 0.08323847502470016\n",
            "filter= [2]drop_first= [0, 1]\n",
            "\n",
            "starting Epoch 3\n",
            "Training...\n",
            "Train loss: 2.5569607615470886\n",
            "Train loss: 1.9934049844741821\n",
            "Train loss: 1.8461829125881195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FhsNu_4X4ewN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}